
"smart_sources:6 - Main Notes/Common Activation Function In Neural Networks.md": {"path":"6 - Main Notes/Common Activation Function In Neural Networks.md","last_embed":{"hash":null},"embeddings":{},"last_read":{"hash":"1hry12g","at":1755153825012},"class_name":"SmartSource","last_import":{"mtime":1744001488289,"size":3146,"at":1755153825015,"hash":"1hry12g"},"blocks":{"#":[1,5],"## Common Activation Functions in Neural Networks":[6,132],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)":[8,53],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Definition":[10,14],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Definition#{1}":[12,12],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Definition#{2}":[13,14],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Mathematical Representation":[15,18],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Mathematical Representation#{1}":[17,18],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Key Characteristics":[19,25],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Key Characteristics#{1}":[21,21],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Key Characteristics#{2}":[22,22],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Key Characteristics#{3}":[23,23],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Key Characteristics#{4}":[24,25],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Application Domains":[26,40],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Application Domains#{1}":[28,31],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Application Domains#{2}":[32,35],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Application Domains#{3}":[36,40],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Advantages":[41,47],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Advantages#{1}":[43,43],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Advantages#{2}":[44,44],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Advantages#{3}":[45,45],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Advantages#{4}":[46,47],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Limitations":[48,53],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Limitations#{1}":[50,50],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Limitations#{2}":[51,51],"## Common Activation Functions in Neural Networks#ReLU (Rectified Linear Unit)#Limitations#{3}":[52,53],"## Common Activation Functions in Neural Networks#Variants: Leaky ReLU vs ELU":[54,72],"## Common Activation Functions in Neural Networks#Variants: Leaky ReLU vs ELU#Leaky ReLU":[56,61],"## Common Activation Functions in Neural Networks#Variants: Leaky ReLU vs ELU#Leaky ReLU#{1}":[58,58],"## Common Activation Functions in Neural Networks#Variants: Leaky ReLU vs ELU#Leaky ReLU#{2}":[59,59],"## Common Activation Functions in Neural Networks#Variants: Leaky ReLU vs ELU#Leaky ReLU#{3}":[60,61],"## Common Activation Functions in Neural Networks#Variants: Leaky ReLU vs ELU#ELU (Exponential Linear Unit)":[62,68],"## Common Activation Functions in Neural Networks#Variants: Leaky ReLU vs ELU#ELU (Exponential Linear Unit)#{1}":[64,64],"## Common Activation Functions in Neural Networks#Variants: Leaky ReLU vs ELU#ELU (Exponential Linear Unit)#{2}":[65,65],"## Common Activation Functions in Neural Networks#Variants: Leaky ReLU vs ELU#ELU (Exponential Linear Unit)#{3}":[66,66],"## Common Activation Functions in Neural Networks#Variants: Leaky ReLU vs ELU#ELU (Exponential Linear Unit)#{4}":[67,68],"## Common Activation Functions in Neural Networks#Variants: Leaky ReLU vs ELU#Comparative Selection":[69,72],"## Common Activation Functions in Neural Networks#Variants: Leaky ReLU vs ELU#Comparative Selection#{1}":[71,71],"## Common Activation Functions in Neural Networks#Variants: Leaky ReLU vs ELU#Comparative Selection#{2}":[72,72],"## Common Activation Functions in Neural Networks#Other Common Function":[73,132],"## Common Activation Functions in Neural Networks#Other Common Function#1. Sigmoid":[75,84],"## Common Activation Functions in Neural Networks#Other Common Function#1. Sigmoid#{1}":[78,79],"## Common Activation Functions in Neural Networks#Other Common Function#1. Sigmoid#{2}":[80,80],"## Common Activation Functions in Neural Networks#Other Common Function#1. Sigmoid#{3}":[81,81],"## Common Activation Functions in Neural Networks#Other Common Function#1. Sigmoid#{4}":[82,82],"## Common Activation Functions in Neural Networks#Other Common Function#1. Sigmoid#{5}":[83,84],"## Common Activation Functions in Neural Networks#Other Common Function#2. Tanh (Hyperbolic Tangent)":[85,93],"## Common Activation Functions in Neural Networks#Other Common Function#2. Tanh (Hyperbolic Tangent)#{1}":[87,88],"## Common Activation Functions in Neural Networks#Other Common Function#2. Tanh (Hyperbolic Tangent)#{2}":[89,89],"## Common Activation Functions in Neural Networks#Other Common Function#2. Tanh (Hyperbolic Tangent)#{3}":[90,90],"## Common Activation Functions in Neural Networks#Other Common Function#2. Tanh (Hyperbolic Tangent)#{4}":[91,91],"## Common Activation Functions in Neural Networks#Other Common Function#2. Tanh (Hyperbolic Tangent)#{5}":[92,93],"## Common Activation Functions in Neural Networks#Other Common Function#3. Softmax":[94,101],"## Common Activation Functions in Neural Networks#Other Common Function#3. Softmax#{1}":[96,97],"## Common Activation Functions in Neural Networks#Other Common Function#3. Softmax#{2}":[98,98],"## Common Activation Functions in Neural Networks#Other Common Function#3. Softmax#{3}":[99,99],"## Common Activation Functions in Neural Networks#Other Common Function#3. Softmax#{4}":[100,101],"## Common Activation Functions in Neural Networks#Other Common Function#4. Swish":[102,108],"## Common Activation Functions in Neural Networks#Other Common Function#4. Swish#{1}":[104,104],"## Common Activation Functions in Neural Networks#Other Common Function#4. Swish#{2}":[105,105],"## Common Activation Functions in Neural Networks#Other Common Function#4. Swish#{3}":[106,106],"## Common Activation Functions in Neural Networks#Other Common Function#4. Swish#{4}":[107,108],"## Common Activation Functions in Neural Networks#Other Common Function#5. GELU (Gaussian Error Linear Unit)":[109,116],"## Common Activation Functions in Neural Networks#Other Common Function#5. GELU (Gaussian Error Linear Unit)#{1}":[111,112],"## Common Activation Functions in Neural Networks#Other Common Function#5. GELU (Gaussian Error Linear Unit)#{2}":[113,113],"## Common Activation Functions in Neural Networks#Other Common Function#5. GELU (Gaussian Error Linear Unit)#{3}":[114,114],"## Common Activation Functions in Neural Networks#Other Common Function#5. GELU (Gaussian Error Linear Unit)#{4}":[115,116],"## Common Activation Functions in Neural Networks#Other Common Function#6. PReLU (Parametric ReLU)":[117,132],"## Common Activation Functions in Neural Networks#Other Common Function#6. PReLU (Parametric ReLU)#{1}":[119,120],"## Common Activation Functions in Neural Networks#Other Common Function#6. PReLU (Parametric ReLU)#{2}":[121,121],"## Common Activation Functions in Neural Networks#Other Common Function#6. PReLU (Parametric ReLU)#{3}":[122,122],"## Common Activation Functions in Neural Networks#Other Common Function#6. PReLU (Parametric ReLU)#{4}":[123,124],"## Common Activation Functions in Neural Networks#Other Common Function#6. PReLU (Parametric ReLU)#{5}":[125,126],"## Common Activation Functions in Neural Networks#Other Common Function#6. PReLU (Parametric ReLU)#{6}":[127,127],"## Common Activation Functions in Neural Networks#Other Common Function#6. PReLU (Parametric ReLU)#{7}":[128,128],"## Common Activation Functions in Neural Networks#Other Common Function#6. PReLU (Parametric ReLU)#{8}":[129,132],"#References":[133,134]},"outlinks":[{"title":"classification","target":"classification","line":4},{"title":"DeepLearning","target":"DeepLearning","line":4},{"title":"Machine Learning","target":"Machine Learning","line":4},{"title":"Neural Networks","target":"Neural Networks","line":4},{"title":"regression","target":"regression","line":4},{"title":"classification","target":"classification","line":33}],"task_lines":[]},