2025-04-21 11:28


Tags: [[Model Generalization]], [[data scientist]]

# Normalizing Inputs
### Normalizing Training set
![[Pasted image 20250421113310.png]]
#### **BÃªn trÃ¡i (Raw data - Dá»¯ liá»‡u gá»‘c)**
Biá»ƒu Ä‘á»“ nÃ y hiá»ƒn thá»‹ dá»¯ liá»‡u ban Ä‘áº§u chÆ°a qua chuáº©n hÃ³a, vá»›i trá»¥c hoÃ nh lÃ  `xâ‚` vÃ  trá»¥c tung lÃ  `xâ‚‚`.
- GiÃ¡ trá»‹ `xâ‚` dao Ä‘á»™ng tá»« khoáº£ng `0` Ä‘áº¿n `5`, trong khi `xâ‚‚` chá»‰ tá»« khoáº£ng `0` Ä‘áº¿n `3`.
- Äiá»u nÃ y khiáº¿n scale giá»¯a cÃ¡c feature (Ä‘áº·c trÆ°ng) lá»‡ch nhau â†’ gÃ¢y khÃ³ khÄƒn cho mÃ´ hÃ¬nh khi há»c, Ä‘áº·c biá»‡t lÃ  thuáº­t toÃ¡n dá»±a vÃ o khoáº£ng cÃ¡ch (nhÆ° KNN, gradient descent...).

#### **Giá»¯a (Sau khi trá»« mean)**

BÆ°á»›c Ä‘áº§u tiÃªn lÃ  **trá»« trung bÃ¬nh (subtract mean)** Ä‘á»ƒ Ä‘Æ°a dá»¯ liá»‡u vá» trung tÃ¢m quanh gá»‘c tá»a Ä‘á»™ (mean = 0).
**CÃ´ng thá»©c:**

$$Î¼= \frac{1}{m} \sum_{i=1}^{m} x^{(i)}, \quad x := xâˆ’Î¼$$
- TÃ­nh trung bÃ¬nh (mean) cá»§a tá»«ng feature.
- Trá»« mean khá»i tá»«ng giÃ¡ trá»‹ tÆ°Æ¡ng á»©ng.
- Sau bÆ°á»›c nÃ y, cÃ¡c feature cÃ³ trung bÃ¬nh báº±ng 0, nhÆ°ng váº«n cÃ²n scale khÃ¡c nhau.

ğŸ“Œ DÃ²ng dÆ°á»›i ghi:

> â€œUse same Î¼ to normalize test set.â€  
> â†’ NghÄ©a lÃ  ta cÅ©ng pháº£i **dÃ¹ng mean cá»§a táº­p train Ä‘á»ƒ chuáº©n hÃ³a táº­p test**.

---

#### ğŸ“ **BÃªn pháº£i (Sau khi chuáº©n hÃ³a phÆ°Æ¡ng sai - Normalize variance)**

Tiáº¿p theo lÃ  chuáº©n hÃ³a phÆ°Æ¡ng sai Ä‘á»ƒ Ä‘Æ°a scale cá»§a cÃ¡c feature vá» giá»‘ng nhau (variance â‰ˆ 1).

**CÃ´ng thá»©c:**

$$Ïƒ2= \frac{1}{m} \sum_{i=1}^{m} x^{(i)} \circ x^{(i)}, \quad x: =Ïƒx$$
- TÃ­nh Ä‘á»™ lá»‡ch chuáº©n `Ïƒ` theo tá»«ng feature (element-wise).    
- Chia dá»¯ liá»‡u cho `Ïƒ`.    

Káº¿t quáº£: Cáº£ `xâ‚` vÃ  `xâ‚‚` giá» Ä‘á»u cÃ³ **mean = 0** vÃ  **variance â‰ˆ 1** â†’ giÃºp mÃ´ hÃ¬nh há»c nhanh vÃ  á»•n Ä‘á»‹nh hÆ¡n.

---

### ğŸ“Œ **TÃ³m táº¯t quy trÃ¬nh chuáº©n hÃ³a (Normalization):**

1. **TÃ­nh trung bÃ¬nh `Î¼` cho tá»«ng feature.**
2. **Trá»« `Î¼` khá»i dá»¯ liá»‡u â†’ mean = 0.**
3. **TÃ­nh Ä‘á»™ lá»‡ch chuáº©n `Ïƒ`.*    
4. **Chia dá»¯ liá»‡u cho `Ïƒ` â†’ variance = 1.**    
5. **DÃ¹ng cÃ¹ng `Î¼` vÃ  `Ïƒ` Ä‘á»ƒ chuáº©n hÃ³a táº­p test.**
### Why normalizing inputs?

![[Pasted image 20250421113836.png]]
- Viá»‡c khÃ´ng normalizing sáº½ khiáº¿n hÃ m loss $J(w, b)$ cÃ³ hÃ¬nh dáº¡ng mÃ©o mÃ³, khiáº¿n cho quÃ¡ trÃ¬nh há»™i tá»¥ khÃ´ng á»•n Ä‘á»‹nh. 
## **BÃªn trÃ¡i: Unnormalized (KhÃ´ng chuáº©n hÃ³a)**

###  HÃ¬nh dáº¡ng hÃ m máº¥t mÃ¡t (`J`)
- HÃ¬nh elip dÃ i, dáº¹t â†’ cÃ¡c Ä‘Æ°á»ng Ä‘á»“ng má»©c (contour) bá»‹ **kÃ©o dÃ i** theo 1 hÆ°á»›ng.
- Gradient descent khÃ³ tÃ¬m Ä‘Æ°á»ng Ä‘i ngáº¯n â†’ pháº£i "zigzag" ráº¥t nhiá»u Ä‘á»ƒ tá»›i Ä‘Æ°á»£c Ä‘iá»ƒm cá»±c tiá»ƒu.    
###  ÄÆ°á»ng Ä‘i gradient
- ÄÆ°á»ng Ä‘i láº¯c ngoáº±n ngoÃ¨o.
- Máº¥t **nhiá»u bÆ°á»›c** Ä‘á»ƒ há»™i tá»¥.    
- NguyÃªn nhÃ¢n: Scale cá»§a cÃ¡c Ä‘áº·c trÆ°ng khÃ´ng giá»‘ng nhau (vÃ­ dá»¥ `xâ‚ âˆˆ [1, 1000]`, `xâ‚‚ âˆˆ [0, 1]`).

##  **BÃªn pháº£i: Normalized (ÄÃ£ chuáº©n hÃ³a)**

###  HÃ¬nh dáº¡ng hÃ m máº¥t mÃ¡t (`J`)

- TrÃ´ng nhÆ° hÃ¬nh bÃ¡t Ãºp trÃ²n, Ä‘á»‘i xá»©ng â†’ contour lÃ  **Ä‘Æ°á»ng trÃ²n Ä‘á»“ng tÃ¢m**.
- Gradient descent dá»… tÃ¬m Ä‘Æ°á»ng Ä‘i ngáº¯n nháº¥t Ä‘áº¿n cá»±c tiá»ƒu.

###  ÄÆ°á»ng Ä‘i gradient
- Trá»±c tiáº¿p, nhanh chÃ³ng.
- Há»™i tá»¥ **nhanh hÆ¡n nhiá»u**.

|                                | **Káº¿t luáº­n:**                          |
| ------------------------------ | -------------------------------------- |
| Before normalizing             | After normalizing                      |
| HÃ m loss mÃ©o mÃ³                | HÃ m loss Ä‘á»‘i xá»©ng, dá»… tá»‘i Æ°u           |
| Gradient descent khÃ´ng á»•n Ä‘á»‹nh | Gradient descent á»•n Ä‘á»‹nh, há»™i tá»¥ nhanh |


# References
