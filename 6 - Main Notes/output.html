<p>2025-04-23 22:04</p>
<p>Tags:</p>
<h1
id="early-wildfire-detection-with-cubesat-images-using-single-image-super-resolution">Early
Wildfire Detection with CubeSat Images Using Single Image
Super-Resolution</h1>
<ul>
<li><strong>Abstract summary</strong>: Bài báo trình bày một phương pháp
mới để phát hiện cháy rừng sớm bằng hình ảnh từ vệ tinh CubeSat, kết hợp
giữa <strong>deep learning</strong> và <strong>kỹ thuật tăng độ phân
giải (super-resolution)</strong>.
<ul>
<li>Note: <strong>Dữ liệu là ảnh từ vệ tinh Landsat-8</strong>, được xử
lý thành ảnh RGB và <strong>giả lập ảnh CubeSat</strong> bằng cách
<strong>giảm chất lượng</strong>, rồi <strong>tăng lại độ phân giải bằng
Real-ESRGAN</strong>. <strong>Mục tiêu</strong> là tạo ra một giải pháp
có thể áp dụng tốt <strong>cho ảnh CubeSat trong thực tế</strong></li>
</ul></li>
<li><strong>Cách tiếp cận:</strong>
<ul>
<li>Dùng ảnh RGB được tạo từ ảnh Landsat-8 (ban đầu có 10 kênh phổ, sau
đó chuyển thành 3 kênh RGB).</li>
<li>Ảnh được nâng cấp độ phân giải gấp 4 lần bằng kỹ thuật
<strong>Real-ESRGAN</strong>.</li>
<li>Áp dụng transfer learning với hai mô hình pre-trained:
<strong>MobileNetV2</strong> và <strong>ResNet152V2</strong>.</li>
</ul></li>
<li><strong>Kết quả:</strong> Việc nâng cấp độ phân giải ảnh giúp tăng
độ chính xác, độ nhạy (recall) và f1-score khi phát hiện cháy rừng, tăng
khoảng <strong>3–5%</strong> tùy mô hình. ### Introduction Summary</li>
<li>Nhắc lại về các tác hại của cháy rừng và tính cấp thiết của việc
phát triển mô hình phát hiện cháy rừng</li>
<li>Trình bày lại các phương pháp phát hiện cháy rừng trong quá khứ, có
3 loại:
<ul>
<li><em>dựa trên mặt đất (terrestrial-based), trên không (aerial-based)
và vệ tinh (satellite-based)</em></li>
<li>Dạng mặt đất và trên không phổ biến hơn vì chi phí ban đầu và kỹ
thuật đơn giản hơn.</li>
<li>Tuy nhiên, do số lượng vệ tinh phóng lên tăng mạnh và chi phí giảm,
nghiên cứu về vệ tinh đang được đẩy mạnh.</li>
</ul></li>
<li>Trình bày về các ưu điểm của việc sử dụng vệ tinh:
<ul>
<li>Có thể giám sát những khu vực xa xôi, khó tiếp cận.</li>
<li>Quan sát liên tục cả vào ban đêm hoặc trong thời tiết xấu.</li>
<li>Về lâu dài tiết kiệm chi phí bảo trì so với các phương pháp
khác.</li>
</ul></li>
<li>Trình bày cụ thể về những ưu điểm của <strong>CubeSat</strong>:
<ul>
<li>Giá rẻ, dễ triển khai, mở rộng vùng quan sát trên toàn cầu.</li>
<li>Có thể chọn quỹ đạo để theo dõi nhiều nơi hoặc giám sát liên tục một
khu vực.</li>
<li>Có thể dùng nhiều CubeSat để vượt qua hạn chế về băng thông truyền
tín hiệu.</li>
</ul></li>
<li>Những hạn chế của CubeSat:
<ul>
<li>Kích thước nhỏ nên camera payload capacity nhỏ → không thể sử dụng
thuật toán so sánh nhiều băng tần như các vệ tinh lớn.</li>
<li>Khả năng xử lý phần mềm giới hạn → không thể implementing các mô
hình deep learning nặng.</li>
</ul></li>
<li>Do đó, cần giải pháp nhẹ, hiệu quả và dùng ít dữ liệu đầu vào.
<ul>
<li>=&gt; Bài báo đề xuất dùng kỹ thuật
<strong>super-resolution</strong> để cải thiện hiệu quả phát hiện cháy
rừng từ ảnh CubeSat, dù bị giới hạn về số băng tần và bộ nhớ. ###
Super-resolution technique:</li>
</ul></li>
<li>Kỹ thuật super-resolution sẽ được thực hiện tại trạm ở mặt đất, mà
không cần phải thay đổi bất kỳ phần cứng nào của CubeSat</li>
<li>Mục tiêu là giúp hệ thống <strong>phát hiện cháy rừng thời gian thực
trên toàn cầu bằng CubeSat</strong>.<br />
</li>
<li>Ưu điểm:
<ul>
<li>Khắc phục các giới hạn của CubeSat (kích thước nhỏ, băng thông thấp,
tải trọng hạn chế).</li>
<li>Ảnh RGB từ CubeSat được xử lý nâng cao độ phân giải ở mặt đất → cải
thiện chất lượng ảnh.</li>
<li>Khi so sánh mô hình học sâu trên ảnh gốc và ảnh đã enhanced, kết quả
cho thấy:
<ul>
<li><strong>Tốc độ học nhanh hơn</strong></li>
<li><strong>Hiệu suất phát hiện cháy tốt hơn</strong> ### Materials</li>
</ul></li>
</ul></li>
<li>Dữ liệu dùng cho training được tiền xử lý từ data Landsat-8
<ul>
<li>Ảnh Landsat-8 có 11 băng tần (multispectral), nhưng loại bỏ band 8
(panchromatic), còn lại 10 band → lưu dưới định dạng TIFF.</li>
</ul></li>
<li>Trong nghiên cứu trước đó:
<ul>
<li>Ảnh được <em>resize về kích thước 256x256</em>, với spatial
resolution là 30m thì 1 bức ảnh sẽ tương ứng với <span
class="math inline">59<em>k</em><em>m</em><sup>2</sup></span> diện tích
mặt đất [[Pasted image 20250424124416.png]]</li>
<li>Dùng kỹ thuật segmentation để tạo <strong>fire masks</strong> cho
ảnh (xem rằng liệu có đang xảy ra 1 vụ cháy nào trong từng pixel
không)</li>
<li>Tuy nhiên, gán nhãn thủ công rất khó và tốn thời gian → họ dùng
<strong>3 thuật toán phát hiện cháy có sẵn</strong> để tự động tạo nhãn:
<ul>
<li>Schroeder et al.</li>
<li>Murphy et al.<br />
</li>
<li>Kumar &amp; Roy</li>
</ul></li>
<li>“Since the three algorithms are not ground truth, they sometimes
produce slightly different results”, nên họ <strong>xác định một pixel
là “cháy” nếu ít nhất 2 thuật toán đồng ý.</strong> ### Preprocessing:
[[Pasted image 20250424144817.png]]</li>
</ul></li>
<li>Do hạn chế về khả năng xử lý của CubeSat, kích thước ảnh được giảm
xuống 64x64 pixel và chỉ sử dụng 3 kênh màu RGB thay vì 10 kênh đa phổ.
Bài toán được chuyển từ phân đoạn từng pixel sang phân loại nhị phân (có
cháy/không cháy).</li>
</ul>
<ol type="1">
<li>Giảm kích thước ảnh:
<ul>
<li>Ảnh đã được thu nhỏ xuống kích cỡ 64x64 để phù hợp với khả năng xử
lý của CubeSat, mỗi ảnh giờ đây presents <span
class="math inline">3.7<em>k</em><em>m</em><sup>2</sup></span></li>
</ul></li>
<li>Đổi format:
<ul>
<li>Từ ảnh multispectral 10 band TIFF format -&gt; ảnh 3 band RGB với
PNG format</li>
<li>Sử dụng thư viện GDAL của python để process</li>
<li>Mặc dù có mất một số thông tin khi chuyển từ giá trị float sang
integer ở từng pixel, nhưng ảnh hưởng không đáng kể vì mô hình sử dụng
thông tin đã được chuẩn hóa</li>
</ul></li>
<li>Chia nhỏ và gán nhãn lại:
<ol type="a">
<li>Có ảnh gốc 256x256 và một fire mask tương ứng</li>
</ol>
<ul>
<li>Trong fire mask: Màu trắng = có cháy, màu đen = không cháy</li>
<li>Họ chia ảnh gốc thành 16 ảnh nhỏ (64x64) và cũng chia fire mask
tương ứng thành 16 phần</li>
</ul>
<ol start="2" type="a">
<li>Cách gán nhãn mới:</li>
</ol>
<ul>
<li>Nếu phần fire mask của ảnh nhỏ có bất kỳ điểm trắng nào → ảnh đó
được gán nhãn “có cháy”</li>
<li>Nếu phần fire mask hoàn toàn đen → ảnh đó được gán nhãn “không
cháy”</li>
<li>Assume rằng độ chính xác của các mặt nạ cháy gốc là ground truth và
sử dụng chúng làm cơ sở để tạo bộ dữ liệu phân loại nhị phân mới (chỉ có
2 lớp: có cháy hoặc không có cháy). Điều này đơn giản hóa bài toán để
phù hợp với khả năng xử lý hạn chế của CubeSat. ### Class imbalance</li>
</ul></li>
</ol>
<ul>
<li>Dữ liệu gốc được thiết kế cho pixel-level segmentation nên ngay cả
ảnh chỉ có 1 pixel được classified là cháy thì cũng sẽ được labeled “có
cháy”</li>
<li>Điều này tạo ra class imbalance nghiệm trọng với tỉ lệ 10:1</li>
<li>khi data imbalanced, mô hình có xu hướng biased theo majority class
bởi vì nó đang cố tối ưu hóa độ chính xác tổng thể, dẫn đến hiệu suất
kém trong việc phát hiện cháy rừng (điều quan trọng nhất)</li>
<li><strong>Giải Pháp</strong>: sử dụng undersampling, giảm số lượng mẫu
từ lớp đa số (giảm số ảnh “không cháy”) với các ảnh được chọn ngẫu nhiên
để tránh mất thông tin quan trọng</li>
<li><strong>Kết quả</strong>:
<ul>
<li>Bộ dữ liệu cuối cùng dành cho binary classification deep-learning có
5.966 ảnh với tỷ lệ cân bằng giữa ảnh “có cháy” và “không cháy”</li>
<li>Cùng một tập hình ảnh được sử dụng cho cả quá trình huấn luyện và
kiểm tra, không phụ thuộc vào việc có sử dụng kỹ thuật siêu phân giải
hay không ### Methods: [[Pasted image 20250424144944.png]]</li>
</ul></li>
<li><strong>Early Wildfire Detection Framework</strong>
<ol type="1">
<li><em>Vấn đề với CubeSat</em>: Do CubeSat có hạn chế về khả năng xử lý
bởi vì payload capacity nhỏ, điều này gây khó khăn cho việc xử lý và
detect wildfire onboard
<ul>
<li>=&gt; Giải pháp tốt hơn được đề xuất là gửi ảnh về mặt đất để xử
lý</li>
</ul></li>
<li><em>Vấn đề mới:</em> Ngay cả khi xử lý trên mặt đất, ảnh từ CubeSat
có độ phân giải cố định (fixed resolution). Chỉ dùng các mô hình phức
tạp hơn không đủ để cải thiện hiệu suất vì chất lượng ảnh đầu vào bị
giới hạn.
<ul>
<li>=&gt; Đề xuất <em>super-resolution technique</em>, giúp tăng cường
chất lượng hình ảnh, làm ảnh nét hơn, chi tiết hơn từ ảnh gốc có độ phân
giải thấp.</li>
<li>Nghiên cứu sẽ so sánh hiệu quả phát hiện cháy rừng khi dùng SR so
với khi không dùng SR (trên cùng ảnh và mô hình, flow xử lý dựa theo
Figure2)</li>
</ul></li>
<li>Khó khăn khi áp dụng SR cho ảnh vệ tinh:
<ul>
<li>Hầu hết nghiên cứu SR phát triển trong lĩnh vực thị giác máy tính,
tập trung vào ảnh RGB.</li>
<li>Ảnh vệ tinh thường có nhiều kênh phổ multi-spectrum), bao gồm cả
kênh hồng ngoại (infrared) rất hữu ích cho việc phát hiện cháy rừng. Do
đó, các mô hình SR được pre-trained thường không phù hợp.</li>
<li><em>Tuy nhiên</em>, nghiên cứu này vẫn áp dụng được SR vì đã có bước
preprocess ảnh vệ tinh để chuyển đổi thành ảnh RGB</li>
</ul></li>
</ol></li>
<li><strong>Giải thích về việc chọn Single-image super-resolution over
multi-image super-resolution</strong>
<ul>
<li>Do <strong>băng thông vệ tinh hạn chế</strong> và việc <strong>thu
thập ảnh vệ tinh chụp liên tiếp cùng một đám cháy là cực kỳ khó
khăn</strong>, nghiên cứu đã chọn phương pháp <strong>Siêu phân giải Đơn
ảnh (SISR)</strong> thay vì Đa ảnh (MISR).</li>
<li>Họ sử dụng mô hình học sâu pre-trained <strong>Real-ESRGAN</strong>
để <strong>tăng độ phân giải ảnh lên 4 lần</strong>. Kết quả là chất
lượng ảnh vệ tinh được cải thiện đáng kể, với chi tiết tốt hơn (độ phân
giải hiệu quả tăng từ 30m lên 7.5m), giúp ích cho việc phát hiện cháy
rừng. [[Pasted image 20250424163256.png]]</li>
</ul></li>
<li><strong>Wildfire Detection Learning Models</strong>:
<ul>
<li>Sử dụng 2 mô hình học sâu là: <strong>MobileNetV2</strong> và
<strong>ResNet152V2</strong>.</li>
<li><strong>Số lượng tham số:</strong> MobileNetV2 có khoảng 2.4 triệu
tham số, trong khi ResNet152V2 có tới 58.6 triệu.</li>
<li><strong>Kích thước Mô hình (Model Size - MB):</strong> Kích thước
lưu trữ của MobileNetV2 chỉ là 9.75 MB, nhỏ hơn đáng kể so với 234.44 MB
của ResNet152V2.</li>
</ul></li>
<li><strong>Training và thiết lập tham số mô hình</strong>:
<ul>
<li>Tiến hành <strong>hai lượt train và test riêng biệt</strong> cho
<em>mỗi</em> mô hình (tức là tổng cộng 4 lần huấn luyện chính.</li>
<li>Quá trình huấn luyện kéo dài tối đa <strong>100 epochs</strong>, ảnh
đầu vào được qua các bước <strong>normalizing, data
augmentation</strong> (chỉ lật ảnh, không cắt/xoay), và chọn mô hình tốt
nhất dựa trên <strong>validation loss.</strong> Các siêu tham số cụ thể
như trình tối ưu hóa Adam, tốc độ học 1e-5, và <strong>hàm loss Binary
Cross-entropy</strong> đã được chọn sau khi thử nghiệm. [[Pasted image
20250424195347.png]]</li>
</ul></li>
</ul>
<h3 id="result">Result</h3>
<ul>
<li><strong>Evaluation Metrics</strong>:
<ul>
<li>Sử dụng các metrics chính là: <strong>Precision, Recall và
F1-score</strong></li>
<li>Sử dụng <strong>ROC Curve và chỉ số AUC</strong> để biểu diễn hiệu
suất mô hình [[Pasted image 20250424201112.png]]</li>
</ul></li>
<li><strong>Performance on trained model</strong>
<ul>
<li>4 combinations của 2 mô hình(<em>MobileNetV2 và ResNet152V2</em>)
cùng với 2 kiểu data (<em>Low-res và Super-res</em>) được đánh giá trên
một bộ dữ liệu kiểm tra riêng biệt gồm 1,194 ảnh/bộ dữ liệu.</li>
<li>Kết quả: [[Pasted image 20250424201940.png]] =&gt; Các mô hình sử
dụng ảnh đã được <em>thực hiện super-resolution</em> cho thấy hiệu suất
<em>vượt trội</em> so với các mô hình sử dụng ảnh gốc (độ phân giải thấp
- <em>Low resolution</em>).</li>
<li>Learning performance trên các model Low-res tăng khi model size
tăng, ngược lại learning performance trên các model super-res không thay
đổi khi model size tănng =&gt; Điều này cho thấy ảnh super-res chứa
<em>nhiều thông tin rõ ràng hơn</em>. Ngay cả mô hình nhỏ hơn
(MobileNetV2) cũng có thể học được gần như tất cả các đặc trưng cần
thiết từ super-res training data này, không thua kém nhiều so với mô
hình lớn. =&gt; Khi chất lượng ảnh đầu vào đã tốt (super-res), việc
<em>tăng kích thước training data</em> có thể quan trọng hơn việc
<em>chỉ tăng model size</em>.</li>
</ul>
[[Pasted image 20250424202702.png]]<br />
</li>
<li>Phân tích sâu hơn cho thấy các mô hình có xu hướng báo cháy nhầm
(FP) nhiều hơn bỏ sót (FN), và điều này có thể được khắc phục bằng cách
điều chỉnh ngưỡng hoặc tăng dữ liệu. Mặc dù P/R/F1 tương đương, điểm AUC
cao hơn của ResNet cho thấy nó có khả năng phân biệt tổng thể tốt hơn,
và có thể đạt hiệu suất cao hơn nếu tối ưu ngưỡng quyết định. ###
Conclusion Summary</li>
<li>Bài báo kết luận rằng việc kết hợp <em>Deep learning và
Super-res</em> là một hướng đi <em>hiệu quả</em> để phát hiện cháy rừng
sớm bằng ảnh thu được từ CubeSat, khắc phục các hạn chế của các budget
sattelites. Phương pháp này sử dụng <em>transfer learning</em> bằng cách
tận dụng các mô hình như MobileNetV2/ResNet152V2 và ảnh được tăng cường
chất lượng nhờ <em>Super-res</em> , đã cho thấy <em>cải thiện rõ rệt
(3-5%)</em> về hiệu suất so với dùng ảnh gốc. Nó mở ra tiềm năng cho hệ
thống giám sát cháy toàn cầu, thời gian thực, chi phí thấp. Các hướng
phát triển tiếp theo bao gồm <em>mở rộng bộ dữ liệu, thử nghiệm các hệ
số Super-res khác nhau, tối ưu hóa ngưỡng quyết định cháy</em>, và đặc
biệt là <em>giảm kích thước mô hình cùng tỷ lệ bỏ sót đám cháy</em> để
phù hợp với việc xử lý trên CubeSat. # References</li>
</ul>
