2025-03-18 13:47


Tags: [[Machine Learning]], [[beginner]], 

# Linear Regression

![[Pasted image 20250318134846.png]]
- Ta cÃ³ 1 vÃ­ dá»¥ vá» data giÃ¡ nhÃ  á»Ÿ theo Ä‘áº·c trÆ°ng size in feet^2 nhÆ° trÃªn
![[Pasted image 20250318134941.png]]
- Má»¥c Ä‘Ã­ch lÃ  tÃ¬m 1 Ä‘Æ°á»ng tháº³ng (1 hÃ m sá»‘) cÃ³ thá»ƒ thá»ƒ hiá»‡n Ä‘Æ°á»£c má»‘i liÃªn há»‡ giá»¯a Ä‘áº·c trÆ°ng cá»§a data vÃ  nhÃ£n cá»§a data 
![[Pasted image 20250318135213.png]]
- Giáº£ thuyáº¿t vá» dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c biá»ƒu diá»…n theo hÃ m sá»‘ $y \approx h_{\theta}(x) = \theta_{0} + \theta_{1}x$ 
- Trong Ä‘Ã³:
	- $y$ lÃ  giÃ¡ trá»‹ Ä‘áº§u ra (giÃ¡ nhÃ ).
	- $x$ lÃ  Ä‘áº·c Ä‘iá»ƒm cá»§a nhÃ  (vÃ­ dá»¥: diá»‡n tÃ­ch).
	- $\theta_{0}$â€‹ lÃ  há»‡ sá»‘ cháº·n (intercept).
	- $\theta_{1}$ lÃ  há»‡ sá»‘ gÃ³c (slope), xÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ áº£nh hÆ°á»Ÿng cá»§a Ä‘áº·c Ä‘iá»ƒm $x$ Ä‘áº¿n $y$.
-  Thuáº­t toÃ¡n há»c mÃ¡y sáº½ tÃ¬m ra bá»™ tham sá»‘ tá»‘i Æ°u $\theta$ dá»±a trÃªn táº­p huáº¥n luyá»‡n.
- Khi cÃ³ mÃ´ hÃ¬nh, ta cÃ³ thá»ƒ sá»­ dá»¥ng nÃ³ Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ trá»‹ yyy cho dá»¯ liá»‡u má»›i.
- Náº¿u $h_{\theta}(x)$ lÃ  má»™t hÃ m tuyáº¿n tÃ­nh, phÆ°Æ¡ng phÃ¡p nÃ y Ä‘Æ°á»£c gá»i lÃ  **há»“i quy tuyáº¿n tÃ­nh (linear regression)**.
- Ta cáº§n tá»‘i Æ°u $\theta$ lÃ  bá»Ÿi vÃ¬ mÃ´ hÃ¬nh há»c mÃ¡y dá»± Ä‘oÃ¡n má»™t giÃ¡ trá»‹ $h_{\theta}(x)$ nhÆ°ng cÃ³ thá»ƒ lá»‡ch so vá»›i giÃ¡ trá»‹ thá»±c táº¿ $y$. Äá»™ lá»‡ch nÃ y Ä‘Æ°á»£c Ä‘o báº±ng **hÃ m máº¥t mÃ¡t (loss function)**.![[Pasted image 20250318140703.png]]
- Tá»‘i Æ°u $\theta$ giÃºp giáº£m giÃ¡ trá»‹ $J(\theta)$ do Ä‘Ã³ giÃºp mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng chÃ­nh xÃ¡c hÆ¡n
![[Pasted image 20250318141141.png]]
- Visualize hÃ m há»“i quy vá»›i cÃ¡c giÃ¡ trá»‹ $\theta_{0}$ vÃ  $\theta_{1}$  ngáº«u nhiÃªn
![[Pasted image 20250318141315.png]]
- CÃ¡ch Ä‘á»ƒ chá»n giÃ¡ trá»‹ $\theta_{0}$ vÃ  $\theta_{1}$ há»£p lÃ½ lÃ  chá»n lÃ m sao cho $\theta_{0}$ vÃ  $\theta_{1}$ **gáº§n** vá»›i y trong máº«u huáº¥n luyá»‡n $(x,y)$, vÃ  á»Ÿ Ä‘Ã¢y ta cÃ³ cÃ¢u há»i: "NhÆ° tháº¿ nÃ o lÃ  **gáº§n**?"

![[Pasted image 20250318141629.png]]
![[Pasted image 20250318141644.png]]
- HÃ¬nh trÃªn minh há»a cÃ¡ch mÃ´ hÃ¬nh tÃ¬m Ä‘Æ°á»ng tháº³ng tá»‘t nháº¥t Ä‘á»ƒ giáº£m thiá»ƒu cÃ¡c sai sá»‘ giá»¯a giÃ¡ trá»‹ thá»±c $y(i)$ vÃ  giÃ¡ trá»‹ dá»± Ä‘oÃ¡n $h_{\theta}(x_{i})$
- ÄÆ°á»ng nÃ©t Ä‘á»©t mÃ u Ä‘á» lÃ  Ä‘Æ°á»ng há»“i quy cÃ²n cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u khoanh trÃ²n mÃ u xanh lÃ  giÃ¡ trá»‹ thá»±c táº¿, khoáº£ng cÃ¡ch tá»« cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u thá»±c táº¿ Ä‘áº¿n Ä‘Æ°á»ng dá»± Ä‘oÃ¡n lÃ  sai sá»‘ dá»± Ä‘oÃ¡n $(y_{i}-h_{\theta}(x_{i}))$ 
- dÃ²ng ![[Pasted image 20250318142825.png]] nÃ y nghÄ©a lÃ  min cá»§a tá»•ng bÃ¬nh phÆ°Æ¡ng sai sá»‘ (SSE)
- Sau Ä‘Ã³ ta sáº½ muá»‘n tÃ¬m trung bÃ¬nh cá»§a tá»•ng bÃ¬nh phÆ°Æ¡ng sai sá»‘ lÃ  tá»« (SSE) -> (MSE):
$$
\text{MSE} = \frac{1}{m} \sum_{i=1}^{m} (h_{\theta}(x_{i})-y_{i})^2
$$
- VÃ  Ä‘á»ƒ thuáº­n tiá»‡n cho viá»‡c Ä‘áº¡o hÃ m trong *gradient descent* sau Ä‘Ã³, ta sáº½ muá»‘n thÃªm há»‡ sá»‘ 1/2, do Ä‘Ã³ MSE sáº½ trá»Ÿ thÃ nh: 
 $$
J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_{\theta}(x_{i})-y_{i})^2
$$
vÃ  Ä‘Ã¢y cÅ©ng chÃ­nh lÃ  hÃ m loss mÃ  ta sáº½ muá»‘n **minimize** Ä‘á»ƒ tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh cá»§a mÃ¬nh
**NOTE**: Viá»‡c chuyá»ƒn ta chá»n hÃ m loss lÃ  MSE thay vÃ¬ SSE lÃ  vÃ¬:
- TrÃ¡nh phá»¥ thuá»™c vÃ o sá»‘ lÆ°á»£ng dá»¯ liá»‡u
- Dá»… so sÃ¡nh giá»¯a cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau 
- Äá»‹nh nghÄ©a chÃ­nh xÃ¡c hÆ¡n vá» sai sá»‘:
	- SSE cho tháº¥y tá»•ng sai sá»‘ nhÆ°ng khÃ´ng pháº£n Ã¡nh má»©c Ä‘á»™ sai sá»‘ trung bÃ¬nh trÃªn má»—i Ä‘iá»ƒm dá»¯ liá»‡u.
	- MSE giÃºp ta hiá»ƒu rÃµ **má»™t Ä‘iá»ƒm dá»¯ liá»‡u trung bÃ¬nh bá»‹ dá»± Ä‘oÃ¡n lá»‡ch bao nhiÃªu (bÃ¬nh phÆ°Æ¡ng sai sá»‘)**.
- Há»— trá»£ cÃ¡c thuáº­t toÃ¡n tá»‘i Æ°u hÃ³a má»™t cÃ¡ch dá»… dÃ ng hÆ¡n
	- MSE giÃºp Gradient descent hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh hÆ¡n vÃ  há»™i tá»¥ nhanh hÆ¡n vÃ¬ lÆ°á»£ng dá»¯ liá»‡u sáº½ khÃ´ng quÃ¡ nhiá»u SSE náº¿u máº«u quÃ¡ lá»›n 

![[Pasted image 20250318144522.png]]
![[Pasted image 20250318144744.png]]

- ğŸ”¹ Má»¥c tiÃªu cá»§a Linear Regression lÃ  tÃ¬m vector trá»ng sá»‘ Î¸\thetaÎ¸ sao cho hÃ m dá»± Ä‘oÃ¡n hÎ¸(x)h_\theta(x)hÎ¸â€‹(x) khá»›p vá»›i giÃ¡ trá»‹ thá»±c yyy nháº¥t, báº±ng cÃ¡ch **tá»‘i thiá»ƒu hÃ³a MSE**.
# References
