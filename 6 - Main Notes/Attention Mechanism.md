2025-07-06 01:10


Tags:

# Attention Mechanism

### Pipeline cụ thể của **Seq2Seq + Attention với encoder BiGRU và decoder GRU**
### **1. Input Preprocessing**

- Input sentence (e.g., French) → tokenization
- Convert tokens → word embeddings    
    $x1,x2,...,x_T$​

### **2. Encoder (BiGRU)**

- Mỗi input token được đưa vào một BiGRU:
    
    - GRU đọc **xuôi** → h→t\overrightarrow{h}_th
# References
